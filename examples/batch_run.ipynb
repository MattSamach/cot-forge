{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b680066",
   "metadata": {},
   "source": [
    "# Batch Run Example\n",
    "\n",
    "This example demonstrates how to run build cot Search Results on a batch of question/answer pairs using the CoTBuilder class. Results are saved to a files in jsonl format as well as saved in memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596ce9e5",
   "metadata": {},
   "source": [
    "**Imports**\n",
    "\n",
    "This example will use LMStudio for local model serving and OpenAI for generation via external API. CoT-Forge also supports major LLM providers like Gemini, Groq, and Anthropic. Download LMStudio [here](https://lmstudio.ai/), download a model and run a local server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b80393ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "from cot_forge.llm import LMStudioProvider, OpenAIProvider\n",
    "from cot_forge.reasoning import CoTBuilder, NaiveLinearSearch\n",
    "from cot_forge.reasoning.verifiers import LLMJudgeVerifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49bb533",
   "metadata": {},
   "source": [
    "#### Dataset\n",
    "The dataset we will use is [medical-o1-verifiable-problem by FreedomIntelligence on HuggingFace](https://huggingface.co/datasets/FreedomIntelligence/medical-o1-verifiable-problem). This dataset contains a set of open-ended medical questions and ground truth answers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "053b63a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem #1: An 88-year-old woman with osteoarthritis is experiencing mild epigastric discomfort and has vomited material resembling coffee grounds multiple times. Considering her use of naproxen, what is the most likely cause of her gastrointestinal blood loss?\n",
      "Solution #1: Gastric ulcer\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset(\"FreedomIntelligence/medical-o1-verifiable-problem\", split=\"train[:200]\")\n",
    "problems = ds[\"Open-ended Verifiable Question\"]\n",
    "solutions = ds[\"Ground-True Answer\"]\n",
    "\n",
    "print(f\"Problem #1: {problems[0]}\")\n",
    "print(f\"Solution #1: {solutions[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9481d915",
   "metadata": {},
   "source": [
    "#### Using CoTBuilder class to run batch build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1459cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'l use meta-llama-3-8b-instruct as our search_llm.\n",
    "# gpt-4o will be used for the verifier.\n",
    "llama = LMStudioProvider(model_name=\"meta-llama-3-8b-instruct\")\n",
    "gpt_4o = OpenAIProvider(model_name=\"gpt-4o\")\n",
    "\n",
    "builder = CoTBuilder(\n",
    "    search_llm=gpt_4o, # generates reasoning steps\n",
    "    search=NaiveLinearSearch(), # Naive linear search chooses random reasoning steps in a chain\n",
    "    verifier=LLMJudgeVerifier(llm_provider=llama, strict=False), # llama to verify answers\n",
    "    post_processing_llm=llama, # converts reasoning into natural language\n",
    "    dataset_name=\"medical-o1-verifiable-problem\", # dataset name, used for folder structure\n",
    "    base_dir= \"./data\", # base directory to save the results\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b4c1ee",
   "metadata": {},
   "source": [
    "Let's process our dataset using the process_batch() method of CoTBuilder. This method can be run with multi-threading to speed up the process or with a single thread. Because we supplied a dataset_name parameter, the results will be saved to a file in jsonl format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "275242d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multi-thread processing question and ground truth answer pairs.: 100%|██████████| 20/20 [09:02<00:00, 27.11s/pair]\n"
     ]
    }
   ],
   "source": [
    "results = builder.process_batch(\n",
    "    questions=problems, # List of questions\n",
    "    ground_truth_answers=solutions, # List of ground truth answers\n",
    "    multi_thread=True, # Use multi-threading for processing\n",
    "    max_workers=4, # Number of workers to use for processing\n",
    "    load_processed=True, # Load previously processed results if available\n",
    "    only_successful=False, # Only process successful results into natural language\n",
    "    overwrite=True, # Overwrite existing results if any collisions occur\n",
    "    limit=20 # Limit the number of questions to process\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd999f24",
   "metadata": {},
   "source": [
    "#### Examining results\n",
    "\n",
    "Results are returned as a list of tuples, each with a [SearchResult](../src/cot_forge/reasoning/types.py#L137) object and a dictionary with the natural language reasoning text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f99fe0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SearchResult(success=True, question=A 46-year-old Caucasian male w..., num_terminal_nodes=1, num_successful_nodes=1, successful_answers=[\"The most appropriate initial diagnostic test for this patient's acute neurological condition is a CT scan of the head. It offers a rapid evaluation to identify any significant lesions or hemorrhages.\"])\n"
     ]
    }
   ],
   "source": [
    "sample_result, reasoning = results[7]\n",
    "print(sample_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfa0c50",
   "metadata": {},
   "source": [
    "Our search result was a success! Let's dig in further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4ae4c94b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: ReasoningNode(strategy=initialize, success=False, final=False, cot_steps=4)\n",
      "Step 1: ReasoningNode(strategy=explore_new_paths, success=True, final=True, cot_steps=6)\n"
     ]
    }
   ],
   "source": [
    "# Each SearchResult object contains a list of terminal nodes.\n",
    "# Because we used a linear search, there is only one chain and therefore one terminal node.\n",
    "terminal_node = sample_result.terminal_nodes[0]\n",
    "for i, node in enumerate(terminal_node.get_full_node_chain()):\n",
    "  print(f\"Step {i}: {node}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aaa836e",
   "metadata": {},
   "source": [
    "### Natural language reasoning\n",
    "Let's examine the natural language reasoning text from our sample result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b11a9698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<thinking>\n",
      "Hmm, an HIV patient with a low CD4 count and neurological symptoms - that's a red flag. The sudden onset of right hand weakness and high fever makes me think something's going on in his brain.\n",
      "\n",
      "Oh, I need to consider what could be causing this. Given the patient's history and symptoms, conditions like cerebral toxoplasmosis, primary CNS lymphoma, or progressive multifocal leukoencephalopathy (PML) come to mind. And with that fever, it's likely an infectious process is at play.\n",
      "\n",
      "Wait a minute... in acute settings like this, speed is crucial. We need something quick and dirty to guide our next steps. MRI would be ideal for getting a detailed picture of what's going on in his brain, but it's not the fastest option.\n",
      "\n",
      "Actually, a CT scan might be just what we need here. It's quicker than an MRI and can give us some immediate information about major lesions or hemorrhages. Plus, it can rule out life-threatening issues right off the bat.\n",
      "\n",
      "Also, considering the patient's history of incomplete medication adherence, I'm worried about missed opportunities for treatment. A CT scan could help identify any changes in his brain that might be related to an opportunistic infection.\n",
      "\n",
      "Hmm... I think a CT scan is our best bet here. It offers a rapid evaluation to identify significant lesions or hemorrhages and can guide our next steps.</thinking>\n",
      "\n",
      "A CT scan would be the most appropriate initial diagnostic test in this patient due to its rapid evaluation capabilities and ability to rule out life-threatening issues such as hemorrhages or significant lesions. It can also guide further testing and treatment decisions, taking into account the patient's history of incomplete medication adherence and potential opportunistic infections.\n"
     ]
    }
   ],
   "source": [
    "print(reasoning['chain_of_thought_responses'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aeb8b9d",
   "metadata": {},
   "source": [
    "#### Results storage\n",
    "\n",
    "In our CoTBuilder object, we specified `dataset_name=\"medical-o1-verifiable-problem\"` and `base_dir= \"./data\"`. This means that the results will be saved to a folder called `./data/medical-o1-verifiable-problem` in the current working directory. Additionally, another folder at `./data/medical-o1-verifiable-problem/naive_linear_search` was created to store the results of the naive linear search. If a different search algorithm were used, the folder name would reflect that and results would be stored there instead to avoid overwriting.\n",
    "\n",
    "Generally, the results will be saved in a folder structure like this:\n",
    "\n",
    "```bash\n",
    "base_dir/\n",
    "└── dataset_name/\n",
    "    ├── search_algorithm/\n",
    "    │   ├── config.json\n",
    "    │   ├── metadata.json\n",
    "    │   ├── results.jsonl\n",
    "    │   └── reasoning.jsonl\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "14d8fbe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['reasoning.jsonl', 'config.json', 'metadata.json', 'results.jsonl']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(os.listdir(\"./data/medical-o1-verifiable-problem/naive_linear_search\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824c2c2e",
   "metadata": {},
   "source": [
    "The files contain the following information:\n",
    "- `config.json`: The configuration of the CoTBuilder object used to run the search.\n",
    "- `metadata.json`: Metadata about search progress such as completed items, successful items, last updated time, etc.\n",
    "- `results.jsonl`: Serialized [SearchResult](../src/cot_forge/reasoning/types.py#L137) objects in jsonl format. They can be deserialized using the SearchResult.deserialize() method.\n",
    "- `reasoning.jsonl`: Dictionaries with the natural language reasoning text. Each dictionary contains the following keys:\n",
    "  - `question`: The question that was asked.\n",
    "  - `ground_truth`: The answer that was given.\n",
    "  - `chain_of_thought_responses`: A list of strings, representing the processed reasoning text for each stored chain in a processed question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "97db658e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'search_llm': {'model_name': 'gpt-4o', 'input_token_limit': None, 'output_token_limit': None}, 'post_processing_llm': {'model_name': 'meta-llama-3-8b-instruct', 'input_token_limit': None, 'output_token_limit': None}, 'search': {'class_name': 'NaiveLinearSearch', 'name': 'naive_linear_search', 'description': 'A sequential search algorithm that randomly selects and applies reasoning strategies to build a chain of thought. Continues until verification succeeds or max depth is reached.', 'max_depth': 3}, 'verifier': {'name': 'llm_judge_verifier', 'description': 'A basic LLM judge verifier that compares a final answer with a ground truth answer.', 'llm_provider': {'model_name': 'meta-llama-3-8b-instruct', 'input_token_limit': None, 'output_token_limit': None}, 'llm_kwargs': {}, 'prompt_template': 'You are an answer judge.\\nYou are tasked with verifying the correctness of an answer to a question.\\nVerify if the provided answer successfully matches the ground truth answer.\\nThey do not need to be identical, but they should convey the same meaning. (e.g., \"the answer is leukemia\" and \"leukemia\" are equivalent).\\nAnswer with \"yes\" or \"no\" and provide a detailed (a few sentences) explanation.\\nMake sure to include the reasoning behind your decision.\\n\\nQuestion that was asked: {question}\\nProvided answer: {final_answer}\\nGround truth answer: {ground_truth_answer}\\n'}, 'scorer': None, 'strategy_registry': {'strategies': {'initialize': {'name': 'initialize', 'description': 'responding to the above question <question> using the Chain of Thought (CoT) reasoning method. Because this is the initial reasoning, do not start with the `Review` step. Instead, begin with the `Inner Thinking` step and then conclude with the `Final Conclusion` step.', 'is_initial': True, 'minimum_depth': 0}, 'backtrack': {'name': 'backtrack', 'description': 'refining the reasoning using **backtracking** to revisit earlier points of reasoning.', 'is_initial': False, 'minimum_depth': 2}, 'explore_new_paths': {'name': 'explore_new_paths', 'description': 'refining the reasoning by **exploring new approaches** to solving this problem.', 'is_initial': False, 'minimum_depth': 0}, 'correction': {'name': 'correction', 'description': 'refining the reasoning by making precise **corrections** to address prior flaws.', 'is_initial': False, 'minimum_depth': 0}, 'validation': {'name': 'validation', 'description': 'refining the reasoning by conducting a thorough **validation** process to ensure validity.', 'is_initial': False, 'minimum_depth': 0}}}, 'search_llm_kwargs': {}, 'post_processing_llm_kwargs': {}, 'created_at': '2025-05-13T20:56:07.711847', 'dataset_name': 'medical-o1-verifiable-problem', 'search_name': 'naive_linear_search'}\n"
     ]
    }
   ],
   "source": [
    "# Looking at the config file\n",
    "import json\n",
    "\n",
    "with open(\"./data/medical-o1-verifiable-problem/naive_linear_search/config.json\") as f:\n",
    "    config = json.load(f)\n",
    "print(config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cot-forge",
   "language": "python",
   "name": "cot-forge"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
